{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4986aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6055ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "[[3304.2524]]\n"
     ]
    }
   ],
   "source": [
    "ad_spend = np.array([1,2,3,4,5])\n",
    "product_sales = np.array([10,15,20,25,30])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "model.fit(ad_spend,product_sales,epochs=200,verbose=0)\n",
    "\n",
    "print(model.predict(np.array([600])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34cf058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ Customer Age vs Purchase Probability (Sigmoid)\n",
    "# Training Data:\n",
    "# Customer Age: [18, 25, 35, 45, 60]\n",
    "# Purchase Probability: [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "# Question: Build a neural network with 1 hidden layer using sigmoid activation to predict\n",
    "#  the purchase probability for a 50-year-old customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa343a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "[[1.3362535e-06]]\n"
     ]
    }
   ],
   "source": [
    "customer_age = np.array([18,25,35,45,60])\n",
    "purchase_probability = np.array([0.1,0.3,0.5,0.7,0.9])\n",
    "\n",
    "customer_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "customer_model.compile(optimizer = 'sgd',loss='mean_squared_error')\n",
    "\n",
    "customer_model.fit(customer_age,purchase_probability,epochs=200,verbose=0)\n",
    "\n",
    "print(customer_model.predict(np.array([50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c11ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ï¸âƒ£ Study Hours vs Exam Score (ReLU)\n",
    "# Training Data:\n",
    "# Hours Studied: [0, 1, 2, 3, 4, 5]\n",
    "# Exam Score: [0, 20, 40, 60, 80, 100]\n",
    "# Question: Build a neural network using ReLU activation in the \n",
    "# hidden layer to predict the exam score for 6 hours of study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372828d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "[[5.7335196]]\n"
     ]
    }
   ],
   "source": [
    "study_hours = np.array([0,1,2,3,4,5])\n",
    "exam_score = np.array([0,20,40,60,80,100])\n",
    "\n",
    "study_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),  # hidden layer\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "study_model.compile(optimizer='adam',loss='mse')\n",
    "study_model.fit(study_hours, exam_score, epochs=300,verbose=0)\n",
    "print(study_model.predict(np.array([6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959a4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "[[119.70484]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "study_hours = np.array([0,1,2,3,4,5], dtype=float)\n",
    "exam_score = np.array([0,20,40,60,80,100], dtype=float)\n",
    "\n",
    "# Scale the data\n",
    "study_hours_scaled = study_hours / 5\n",
    "exam_score_scaled = exam_score / 100\n",
    "\n",
    "study_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(17, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "study_model.compile(optimizer='adam', loss='mse')\n",
    "study_model.fit(study_hours_scaled, exam_score_scaled, epochs=2000, verbose=0)\n",
    "\n",
    "# Predict for 6 hours\n",
    "pred_scaled = study_model.predict(np.array([6/5]))\n",
    "pred = pred_scaled * 100\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81acf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ Daily Steps vs Calories Burned (Tanh)\n",
    "# Training Data:\n",
    "# Steps: [1000, 3000, 5000, 7000, 10000]\n",
    "# Calories Burned: [50, 150, 250, 350, 500]\n",
    "# Question: Build a neural network with Tanh activation to predict calories burned for 8000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3947021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002652A547EC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "[[413.18130152]]\n"
     ]
    }
   ],
   "source": [
    "steps = np.array([1000, 3000, 5000, 7000, 10000], dtype=float)\n",
    "calories = np.array([50, 150, 250, 350, 500], dtype=float)\n",
    "\n",
    "# Normalize input\n",
    "steps_norm = (steps - steps.mean()) / steps.std()\n",
    "\n",
    "# Normalize output\n",
    "cal_mean = calories.mean()\n",
    "cal_std = calories.std()\n",
    "calories_norm = (calories - cal_mean) / cal_std\n",
    "\n",
    "calories_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(32, activation='tanh'),\n",
    "    tf.keras.layers.Dense(16, activation='tanh'),\n",
    "    tf.keras.layers.Dense(1)   # linear output\n",
    "])\n",
    "\n",
    "calories_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "calories_model.fit(steps_norm, calories_norm, epochs=300, verbose=0)\n",
    "\n",
    "# Predict for 8000 steps\n",
    "value = (8000 - steps.mean()) / steps.std()\n",
    "pred_norm = calories_model.predict(np.array([[value]]))\n",
    "\n",
    "# Denormalize back to actual calories\n",
    "predicted_calories = pred_norm * cal_std + cal_mean\n",
    "print(predicted_calories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7c3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ï¸âƒ£ Advertisement Impressions vs Click Probability (Sigmoid)\n",
    "# Training Data:\n",
    "# Impressions (thousands): [10, 20, 30, 40, 50]\n",
    "# Click Probability: [0.01, 0.05, 0.1, 0.15, 0.2]\n",
    "# Question: Build a neural network with sigmoid activation in the\n",
    "#  output layer to predict click probability for 60k impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f6444fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "[[0.39966747]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "impressions = np.array([10,20,30,40,50])\n",
    "click_probability = np.array([0.01,0.05,0.1,0.15,0.2])\n",
    "\n",
    "# Scale inputs\n",
    "impressions_scaled = impressions / 100\n",
    "new_input = np.array([60]) / 100\n",
    "\n",
    "click_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "click_model.compile(optimizer='adam', loss='mse')\n",
    "click_model.fit(impressions_scaled, click_probability, epochs=500, verbose=0)\n",
    "\n",
    "print(click_model.predict(new_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7ï¸âƒ£ Social Media Posts vs Engagement (Leaky ReLU)\n",
    "# Training Data:\n",
    "# Posts per Day: [1, 2, 3, 4, 5]\n",
    "# Engagement Score: [10, 20, 30, 40, 50]\n",
    "# Question: Build a neural network with Leaky ReLU to predict engagement if 0 posts are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58458a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000245C7898A40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "posts = np.array([[1],[2],[3],[4],[5]])\n",
    "engagement = np.array([[10],[20],[30],[40],[50]])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1, use_bias=False)   # perfect linear mapping\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(posts, engagement, epochs=500, verbose=0)\n",
    "\n",
    "print(model.predict(np.array([[0]])))  # fixed shape, no retracing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ee022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ Movie Ratings vs Viewer Satisfaction (Tanh)\n",
    "# Training Data:\n",
    "# Ratings (1-5): [1, 2, 3, 4, 5]\n",
    "# Satisfaction Score (-1 to 1): [-0.9, -0.5, 0, 0.5, 0.9]\n",
    "# Question: Build a neural network using Tanh activation to predict satisfaction for a rating of 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04d6e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "[[0.32061324]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "ratings = np.array([1,2,3,4,5])\n",
    "satisfaction = np.array([-0.9,-0.5,0,0.5,0.9])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(8, activation='tanh'),\n",
    "    tf.keras.layers.Dense(1, activation='tanh')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(ratings, satisfaction, epochs=2000, verbose=0)\n",
    "\n",
    "print(model.predict(np.array([[3.5]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd62073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9ï¸âƒ£ Product Ratings vs Purchase Likelihood (Softmax)\n",
    "# Training Data (multi-class scenario):\n",
    "# Ratings (3 products): [[1,2,3], [2,3,4], [3,4,5]]\n",
    "# Question: Build a neural network using Softmax in the \n",
    "# output layer to predict probability distribution for [2,3,4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080d9222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Softmax Probability Distribution:\n",
      "[[0.23512796 0.33157203 0.4333    ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3],\n",
    "                      [2,3,4],\n",
    "                      [3,4,5]])\n",
    "\n",
    "y = np.array([0,1,2])\n",
    "\n",
    "y_onehot = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "modelr = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),       # Input layer: 3 numbers per sample\n",
    "    tf.keras.layers.Dense(8, activation='relu'),  # Hidden layer\n",
    "    tf.keras.layers.Dense(3, activation='softmax') # Output: 3-class softmax\n",
    "])\n",
    "\n",
    "\n",
    "modelr.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelr.fit(x, y_onehot, epochs=500, verbose=0)\n",
    "\n",
    "test_input = np.array([[2, 3, 4]])\n",
    "prediction = modelr.predict(test_input)\n",
    "\n",
    "print(\"Softmax Probability Distribution:\")\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb718c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”Ÿ Investment Amount vs Expected Return (Sigmoid)\n",
    "# Training Data:\n",
    "# Investment Amount ($k): [1,2,3,4,5]\n",
    "# Expected Return Probability: [0.1,0.2,0.5,0.7,0.9]\n",
    "# Question: Build a neural network using sigmoid activation in the \n",
    "# output layer to estimate return probability for $6k investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f59d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "[[0.79373777]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Data\n",
    "investment = np.array([[1],[2],[3],[4],[5]])\n",
    "expected = np.array([0.1,0.2,0.5,0.7,0.9])\n",
    "\n",
    "# Scale input\n",
    "scaler = MinMaxScaler()\n",
    "investment_scaled = scaler.fit_transform(investment)\n",
    "\n",
    "# FIXED MODEL: Add hidden layer\n",
    "investment_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "investment_model.compile(optimizer='adam', loss='mse')\n",
    "investment_model.fit(investment_scaled, expected, epochs=500, verbose=0)\n",
    "\n",
    "# Predict scaled 6\n",
    "scaled_6 = scaler.transform(np.array([[6]]))\n",
    "print(investment_model.predict(scaled_6))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
